2025-09-26T07:05:07.731Z [INFO] üêç Python script execution completed - Success: true
2025-09-26T07:05:07.731Z [INFO] üêç Generated 1 files
2025-09-26T07:05:07.732Z [INFO] üêç Generated file: migration-report.md (21879 bytes)
üêç Python script result: {
  success: true,
  output: 'üöÄ Starting migration analysis...\r\n' +
    'üìÅ Repository URL: https://github.com/srigumm/dotnetcore-kafka-integration.git\r\n' +
    'üìÇ Repository Path: C:\\Users\\AbhishekGupta12\\source\\repos\\RepoCloner1\\temp\\clone_1758870032011\r\n' +
    'ü§ñ Using Model: claude-3-5-haiku@20241022\r\n' +
    'üîß Using API Version: 3.5 Haiku\r\n' +
    'üåê Using Endpoint: https://ai-proxy.lab.epam.com/openai/deployments/claude-3-5-haiku@20241022/chat/completions?api-version=3.5 Haiku\r\n' +
    'üìä Phase 1: Repository validation and code loading...\r\n' +
    'ü§ñ Attempting AI analysis...\r\n' +
    'Repository files already exist at C:\\Users\\AbhishekGupta12\\source\\repos\\RepoCloner1\\temp\\clone_1758870032011 (cloned by main application)\r\n' +
    'üìä Total chunks loaded: 16\r\n' +
    'üîç Phase 2: Starting AI-powered analysis...\r\n' +
    'üåê Making API request to: https://ai-proxy.lab.epam.com/openai/deployments/claude-3-5-haiku@20241022/chat/completions?api-version=3.5 Haiku\r\n' +
    "üîß Headers: {'Content-Type': 'application/json', 'Api-Key': 'dial-qux0bkmzf5twpslx680o4gk0fqf', 'User-Agent': 'RepoCloner-AI-Analysis/1.0'}\r\n" +
    "üìã Payload: {'messages': [{'role': 'user', 'content': 'Summarize the purpose and functionality of this code:\\n\\nFile: .gitignore\\n*.swp\\n*.*~\\nproject.lock.json\\n.DS_Store\\n*.pyc\\nnupkg/\\n\\n# Visual Studio Code\\n.vscode\\n\\n# Rider\\n.idea\\n\\n# User-specific files\\n*.suo\\n*.user\\n*.userosscache\\n*.sln.docstates\\n\\n# Build results\\n[Dd]ebug/\\n[Dd]ebugPublic/\\n[Rr]elease/\\n[Rr]eleases/\\nx64/\\nx86/\\nbuild/\\nbld/\\n[Bb]in/\\n[Oo]bj/\\n[Oo]ut/\\nmsbuild.log\\nmsbuild.err\\nmsbuild.wrn\\n\\n# Visual Studio 2015\\n.vs/\\n'}], 'temperature': 0}\r\n" +
    'üîç Response Status: 200\r\n' +
    "üìÑ Response Headers: {'Date': 'Fri, 26 Sep 2025 07:01:04 GMT', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'X-UPSTREAM-ATTEMPTS': '1', 'content-encoding': 'gzip', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains'}\r\n" +
    "‚úÖ Success! Response keys: ['choices', 'usage', 'id', 'created', 'object', 'model']\r\n" +
    'üåê Making API request to: https://ai-proxy.lab.epam.com/openai/deployments/claude-3-5-haiku@20241022/chat/completions?api-version=3.5 Haiku\r\n' +
    "üîß Headers: {'Content-Type': 'application/json', 'Api-Key': 'dial-qux0bkmzf5twpslx680o4gk0fqf', 'User-Agent': 'RepoCloner-AI-Analysis/1.0'}\r\n" +
    `üìã Payload: {'messages': [{'role': 'user', 'content': 'Summarize the purpose and functionality of this code:\\n\\nFile: orderhandler.sln\\n\\ufeff\\nMicrosoft Visual Studio Solution File, Format Version 12.00\\n# Visual Studio 15\\nVisualStudioVersion = 15.0.26124.0\\nMinimumVisualStudioVersion = 15.0.26124.0\\nProject("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "Api", "Api\\\\Api.csproj", "{10995453-869F-4914-B0A0-645259A2D253}"\\nEndProject\\nProject("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "Test", "Test\\\\Test.csproj", "{30ADEE93-305F-4292-8B89-CD2C3683BFD1}"\\nEndProject\\nGlobal\\n\\tGlobalSection(SolutionConfigurationPlatforms) = preSolution\\n\\t\\tDebug|Any CPU = Debug|Any CPU\\n\\t\\tDebug|x64 = Debug|x64\\n\\t\\tDebug|x86 = Debug|x86\\n\\t\\tRelease|Any CPU = Release|Any CPU\\n\\t\\tRelease|x64 = Release|x64\\n\\t\\tRelease|x86 = Release|x86\\n\\tEndGlobalSection\\n\\tGlobalSection(SolutionProperties) = preSolution\\n\\t\\tHideSolutionNode = FALSE\\n\\tEndGlobalSection\\n\\tGlobalSection(ProjectConfigurationPlatforms) = postSolution\\n\\t\\t{10995453-869F-4914-B0A0-645259A2D253}.Debug|Any CPU.ActiveCfg = Debug|Any CPU\\n\\t\\t{10995453-869F-4914-B0A0-645259A2D253}.Debug|Any CPU.Build.0 = Debug|Any CPU\\n\\t\\t{10995453-869F-4914-B0A0-645259A2D253}.Debug|x64.ActiveCfg = Debug|Any CPU\\n\\t\\t{10995453-869F-4914-B0A0-645259A2D253}.Debug|x64.Build.0 = Debug|Any CPU\\n\\t\\t{10995453-869F-4914-B0A0-645259A2D253}.Debug|x86.ActiveCfg = Debug|Any CPU\\n\\t\\t{10995453-869F-4914-B0A0-645259A2D253}.Debug|x86.Build.0 = Debug|Any CPU\\n\\t\\t{10995453-869F-4914-B0A0-645259A2D253}.Release|Any CPU.ActiveCfg = Release|Any CPU\\n\\t\\t{10995453-869F-4914-B0A0-645259A2D253}.Release|Any CPU.Build.0 = Release|Any CPU\\n\\t\\t{10995453-869F-4914-B0A0-645259A2D253}.Release|x64.ActiveCfg = Release|Any CPU\\n\\t\\t{10995453-869F-4914-B0A0-645259A2D253}.Release|x64.Build.0 = Release|Any CPU\\n\\t\\t{10995453-869F-4914-B0A0-645259A2D253}.Release|x86.ActiveCfg = Release|Any CPU\\n\\t\\t{10995453-869F-4914-B0A0-645259A2D253}.Release|x86.Build.0 = Release|Any CPU\\n\\t\\t{30ADEE93-305F-4292-8B89-CD2C3683BFD1}.Debug|Any CPU.ActiveCfg = Debug|Any CPU\\n\\t\\t{30ADEE93-305F-4292-8B89-CD2C3683BFD1}.Debug|Any CPU.Build.0 = Debug|Any CPU\\n\\t\\t{30ADEE93-305F-4292-8B89-CD2C3683BFD1}.Debug|x64.ActiveCfg = Debug|Any CPU\\n\\t\\t{30ADEE93-305F-4292-8B89-CD2C3683BFD1}.Debug|x64.Build.0 = Debug|Any CPU\\n\\t\\t{30ADEE93-305F-4292-8B89-CD2C3683BFD1}.Debug|x86.ActiveCfg = Debug|Any CPU\\n\\t\\t{30ADEE93-305F-4292-8B89-CD2C3683BFD1}.Debug|x86.Build.0 = Debug|Any CPU\\n\\t\\t{30ADEE93-305F-4292-8B89-CD2C3683BFD1}.Release|Any CPU.ActiveCfg = Release|Any CPU\\n\\t\\t{30ADEE93-305F-4292-8B89-CD2C3683BFD1}.Release|Any CPU.Build.0 = Release|Any CPU\\n\\t\\t{30ADEE93-305F-4292-8B89-CD2C3683BFD1}.Release|x64.ActiveCfg = Release|Any CPU\\n\\t\\t{30ADEE93-305F-4292-8B89-CD2C3683BFD1}.Release|x64.Build.0 = Release|Any CPU\\n\\t\\t{30ADEE93-305F-4292-8B89-CD2C3683BFD1}.Release|x86.ActiveCfg = Release|Any CPU\\n\\t\\t{30ADEE93-305F-4292-8B89-CD2C3683BFD1}.Release|x86.Build.0 = Release|Any CPU\\n\\tEndGlobalSection\\nEndGlobal\\n'}], 'temperature': 0}\r\n` +
    'üîç Response Status: 200\r\n' +
    "üìÑ Response Headers: {'Date': 'Fri, 26 Sep 2025 07:01:10 GMT', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'X-UPSTREAM-ATTEMPTS': '1', 'content-encoding': 'gzip', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains'}\r\n" +
    "‚úÖ Success! Response keys: ['choices', 'usage', 'id', 'created', 'object', 'model']\r\n" +
    'üåê Making API request to: https://ai-proxy.lab.epam.com/openai/deployments/claude-3-5-haiku@20241022/chat/completions?api-version=3.5 Haiku\r\n' +
    "üîß Headers: {'Content-Type': 'application/json', 'Api-Key': 'dial-qux0bkmzf5twpslx680o4gk0fqf', 'User-Agent': 'RepoCloner-AI-Analysis/1.0'}\r\n" +
    `üìã Payload: {'messages': [{'role': 'user', 'content': 'Summarize the purpose and functionality of this code:\\n\\nFile: README.md\\n# Building realtime streaming applications using\\xa0.NET Core and\\xa0KAFKA\\n\\n\\n### User Scenario:\\n\\n\\nLet\\'s take a simple use case of e-commerce company. Assume we are building a simple "Order management" APIs to sell products like "Unicorn Whistles".\\n\\n Our objective here is to build a fast & scalable backend APIs to take more order requests and quickly process or trigger other workflows to speedup the delivery process.\\n\\n To address scaling individual apps and other performance related key metrics, lets assume that we have decided to build the below two critical components\\n  - An Order API(RESTful) that takes users orders and responds back immediately with some acknowledgement info.\\n  - A background service that actually process these order requests.\\n\\n### Archgitecutre diagram:\\n![architecture diagram](https://raw.githubusercontent.com/srigumm/dotnetcore-kafka-integration/master/Api/Images/architecture.png)\\n\\n### Prerequisites:\\n\\n - VSCODE or some\\xa0.net code editor\\n - .NET Core 2.1\\n - Docker\\n - KAFKA Installation and Topics setup\\n - Kafkacat command line tool\\n - If you are connecting to Kerberos-aware KAFKA Enterprise Instance, ensure the below things:\\n    - Setup krb5.Conf file  with your organization\\'s KDC details.\\n    - Keep krb5.conf file in default path i.e /etc/ or specify the path with KRB5_CONFIG environment variable.\\n    - Create Keytab file with your principal\\n    - Make sure your/service account has atleast read access to krb5.conf file.\\n\\n### How to install KAFKA in local??\\n- It\\'s easy to setup KAFKA in local using docker containers.\\n  Clone the below below repository and run "docker-compose up" command.\\n        commands:\\n\\n             git clone https://github.com/TribalScale/kafka-waffle-stack.git\\n             cd kafaka-waffle-stack\\n             docker-compose up\\n   Above instructions should start a KAFKA server, and you can use the broker localhost:9092 to produce/consumer messages.\\n- Creating a new topic in local KAFKA:\\n    producing a sample message to a topic using kafkacat utility would create topic if it doesn\\'t exist.\\n    so, run the below command and give some sample message like {"id":1234,"productname":"Unicorn Whistles","quantity":3}\\n\\n       kafkacat -b localhost:9092 -t new_topic -P\\n\\n### Implementation:\\n\\n- Implemented a dotnetcore-WebApi post handler to capture user\\'s order requests.( into "orderrequests" kafka topic)\\n- Implemented a background service(HostedService in .NET core) that process the user\\'s order requests in the "orderrequests" kafka topic and writes to "readytoship" kafka topic.\\n\\n### Run & Test:\\n1. Clone this repository:\\n\\n       git clone https://github.com/srigumm/dotnetcore-kafka-integration.git\\n       cd dotnetcore-kafka-integration\\n2. Run the below commands at the root of your project folder.\\n\\n       dotnet restore\\n       dotnet build\\n       dotnet run"\\n\\n      This should start both webserver for our webapi rest service and  our background service(hosted inside the same webhost).\\n\\n        WebApi URL: http://localhost:5000/api/order\\n\\n3. Use postman to trigger "POST" calls to issue new order requests:\\n         http://localhost:5000/api/order\\n\\n4. Verify if new messages were written to readytoship topic using kafkacat utility:\\n\\n       kafkacat -b localhost:9092 -t readytoship -C\\n\\n### Troubleshooting tips:\\n- If your producer/consumer is not responding at all, then verify your keytab file with below steps\\n\\n      kinit username@MYDOMAIN.COM -k -t username.keytab\\n    you should get authenticated successfully (without being prompted for a password).\\n'}], 'temperature': 0}\r\n` +
    'üîç Response Status: 200\r\n' +
    "üìÑ Response Headers: {'Date': 'Fri, 26 Sep 2025 07:01:18 GMT', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', '"... 80183 more characters,
  error: undefined,
  exitCode: 0,
  generatedFiles: [
    {
      name: 'migration-report.md',
      path: 'C:\\Users\\AbhishekGupta12\\source\\repos\\RepoCloner1\\temp\\clone_1758870032011\\migration-report.md',
      relativePath: 'migration-report.md',
      size: 21879,
      type: 'text',
      mimeType: 'text/markdown',
      createdAt: '2025-09-26T07:05:07.547Z'
    }
  ],
  executionStartTime: 1758870054662,
  executionEndTime: 1758870307717
}
üíæ Creating Python script report...
2025-09-26T07:05:07.743Z [INFO] Successfully parsed migration report: Kafka ‚Üí Azure Service Bus Migration Report
2025-09-26T07:05:07.743Z [INFO] Found 0 Kafka files and 0 code diffs
2025-09-26T07:05:07.744Z [INFO] Created Python script analysis report with 1 generated files
üìä Python script report created - will appear in Reports tab